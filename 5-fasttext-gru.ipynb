{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastText-GRU\n",
    "\n",
    "In this notebook, we utilize pretrained FastText embeddings to create POI embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Embedding, SpatialDropout1D, concatenate\n",
    "from keras.layers import GRU, Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from keras.preprocessing import text, sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\n",
    "    'Active Life', 'Arts & Entertainment', 'Automotive', 'Beauty & Spas',\n",
    "    'Education', 'Event Planning & Services', 'Financial Services', 'Food',\n",
    "    'Health & Medical', 'Home Services', 'Hotels & Travel', 'Local Flavor',\n",
    "    'Local Services', 'Mass Media', 'Nightlife', 'Pets', 'Professional Services',\n",
    "    'Public Services & Government', 'Real Estate', 'Religious Organizations',\n",
    "    'Restaurants', 'Shopping'\n",
    "]\n",
    "\n",
    "train_df = pd.read_csv('data/train.csv', na_filter=False)\n",
    "test_df = pd.read_csv('data/test.csv', na_filter=False)\n",
    "\n",
    "train_texts = train_df['sequence']\n",
    "test_texts = test_df['sequence']\n",
    "\n",
    "train_labels = train_df['categories'].str.get_dummies(sep=', ')\n",
    "test_labels = test_df['categories'].str.get_dummies(sep=', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process sequences via Keras Tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 30000\n",
    "max_len = 256\n",
    "\n",
    "tokenizer = text.Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(train_texts) + list(test_texts))\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(train_texts)\n",
    "X_test = tokenizer.texts_to_sequences(test_texts)\n",
    "\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_len)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_len)\n",
    "\n",
    "y_train = train_labels.values\n",
    "y_test = test_labels.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the embedding matrix, using the pretrained vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download pretrained embeddings from https://www.kaggle.com/yekenot/fasttext-crawl-300d-2m\n",
    "EMBEDDING_FILE = 'ft_models/fasttext-crawl-300d-2M.vec'\n",
    "embed_size = 300\n",
    "\n",
    "def get_coefs(word, *arr): return word, np.asarray(arr, dtype='float32')\n",
    "embedding_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(EMBEDDING_FILE))\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.zeros((nb_words, embed_size))\n",
    "\n",
    "for word, i in list(word_index.items())[:nb_words]:\n",
    "    embedding_vector = embedding_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i-1] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification via a GRU architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input(shape=(max_len, ))\n",
    "x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
    "x = SpatialDropout1D(0.2)(x)\n",
    "x = Bidirectional(GRU(80, return_sequences=True))(x)\n",
    "avg_pool = GlobalAveragePooling1D()(x)\n",
    "max_pool = GlobalMaxPooling1D()(x)\n",
    "conc = concatenate([avg_pool, max_pool])\n",
    "outp = Dense(len(labels), activation='sigmoid')(conc)\n",
    "\n",
    "model = Model(inputs=inp, outputs=outp)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kalexis/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 122961 samples, validate on 30741 samples\n",
      "Epoch 1/2\n",
      " - 860s - loss: 0.0906 - accuracy: 0.9718 - val_loss: 0.0652 - val_accuracy: 0.9801\n",
      "Epoch 2/2\n",
      " - 858s - loss: 0.0605 - accuracy: 0.9813 - val_loss: 0.0608 - val_accuracy: 0.9814\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 2\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, train_size=0.8)\n",
    "\n",
    "hist = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score for class Active Life is 0.9845\n",
      "Test score for class Arts & Entertainment is 0.9813\n",
      "Test score for class Automotive is 0.9839\n",
      "Test score for class Beauty & Spas is 0.9874\n",
      "Test score for class Education is 0.9881\n",
      "Test score for class Event Planning & Services is 0.9668\n",
      "Test score for class Financial Services is 0.9952\n",
      "Test score for class Food is 0.9358\n",
      "Test score for class Health & Medical is 0.9820\n",
      "Test score for class Home Services is 0.9739\n",
      "Test score for class Hotels & Travel is 0.9886\n",
      "Test score for class Local Flavor is 0.9920\n",
      "Test score for class Local Services is 0.9623\n",
      "Test score for class Mass Media is 0.9982\n",
      "Test score for class Nightlife is 0.9823\n",
      "Test score for class Pets is 0.9951\n",
      "Test score for class Professional Services is 0.9740\n",
      "Test score for class Public Services & Government is 0.9958\n",
      "Test score for class Real Estate is 0.9851\n",
      "Test score for class Religious Organizations is 0.9990\n",
      "Test score for class Restaurants is 0.9772\n",
      "Test score for class Shopping is 0.9516\n",
      "Mean test score is 0.9809\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test, batch_size=1024)\n",
    "y_pred = y_pred > 0.5\n",
    "scores = []\n",
    "\n",
    "for label_idx, label_name in enumerate(labels):\n",
    "    test_target = test_labels[label_name]\n",
    "    preds = y_pred[:, label_idx]\n",
    "    score = accuracy_score(test_target, preds)\n",
    "    scores.append(score)\n",
    "    print('Test score for class {} is {:.4f}'.format(label_name, score))\n",
    "\n",
    "print('Mean test score is {:.4f}'.format(np.mean(scores)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
