{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Setup\n",
    "\n",
    "This notebook loads and parses the json file containing the Yelp businesses data to create a well-formed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = './data'\n",
    "BUSINESS_FNAME = 'business.json'\n",
    "\n",
    "CATEGORIES = {\n",
    "    'Active Life', 'Arts & Entertainment', 'Automotive',\n",
    "    'Beauty & Spas', 'Education', 'Event Planning & Services',\n",
    "    'Financial Services', 'Food', 'Health & Medical',\n",
    "    'Home Services', 'Hotels & Travel', 'Local Flavor',\n",
    "    'Local Services', 'Mass Media', 'Nightlife', 'Pets',\n",
    "    'Professional Services', 'Public Services & Government',\n",
    "    'Real Estate', 'Religious Organizations', 'Restaurants',\n",
    "    'Shopping'\n",
    "}\n",
    "\n",
    "# Drop rows that have NA in these columns\n",
    "DROP_NA_COLS = ['business_id', 'categories', 'longitude', 'latitude']\n",
    "# Do not use these columns when constructing POI representation\n",
    "EXCLUDE_COLS = ['business_id', 'categories', 'longitude', 'latitude']\n",
    "\n",
    "TEST_SIZE = 0.2\n",
    "SEED = 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data into a dataframe. We define helper functions to properly handle the nested format of the input json file. We drop POIs without 'business_id', 'categories', 'longitude' or 'latitude'. We only consider the main 22 'CATEGORIES' in the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(192127, 109)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def literal(val):\n",
    "    try:\n",
    "        return literal_eval(val)\n",
    "    except (ValueError, SyntaxError) as e:\n",
    "        return val\n",
    "\n",
    "def flatten_dict(dd, separator='.', prefix=''):\n",
    "    return {prefix + separator + k if prefix else k: v for kk, vv in literal(dd).items() for k, v in\n",
    "            flatten_dict(vv, separator, kk).items()} if isinstance(literal(dd), dict) else {prefix: dd}\n",
    "\n",
    "\n",
    "with open(os.path.join(DATA_ROOT, BUSINESS_FNAME)) as f:\n",
    "    data = [flatten_dict(json.loads(line)) for line in f]\n",
    "df = pd.DataFrame(data)\n",
    "df = df.dropna(subset=DROP_NA_COLS).reset_index(drop=True)\n",
    "df = df.fillna('')\n",
    "df['categories'] = df['categories'].apply(\n",
    "    lambda x: ', '.join([c for c in x.split(', ') if c in CATEGORIES]))\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each POI a sequential representation is extracted based on its attributes. More specifically, this representation consists of the concatenation of the POI's attributes using a <'attr_name'.'attr_value'> format. Attribute values with more than one word are splitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_attr_sequences(df):\n",
    "    cols = df.columns\n",
    "    attrs = df.apply(\n",
    "        lambda x: ' '.join([col + '.' + v for col, val in zip(cols, x)\n",
    "                            if val != '' for v in str(val).split()]), axis=1)\n",
    "    return attrs\n",
    "\n",
    "df['sequence'] = extract_attr_sequences(df.drop(EXCLUDE_COLS, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset to train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((153702, 110), (38425, 110))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = df.sample(frac=1-TEST_SIZE, random_state=SEED)\n",
    "test_df = df.drop(train_df.index).reset_index(drop=True)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "\n",
    "train_df.to_csv(os.path.join(DATA_ROOT, 'train.csv'), index=False)\n",
    "test_df.to_csv(os.path.join(DATA_ROOT, 'test.csv'), index=False)\n",
    "\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
